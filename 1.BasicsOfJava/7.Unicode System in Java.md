# Unicode System in Java

*28 Apr 2025 | 3 min read*

---

Computer systems internally store data in binary representation. A character is stored using a combination of 0's and 1's. The process is called **encoding**. A character encoding scheme is important because it helps to represent the same information on multiple types of devices.

## Types of Encoding

Before the Unicode system, several encoding schemes were used, including:

- **ASCII** (American Standard Code for Information Interchange): used for the United States  
- **ISO 8859-1**: used for Western European languages  
- **KOI-8**: used for Russian  
- **GB18030** and **BIG-5**: used for Chinese  
- **Base64**: used for binary to text encoding  

## Why Does Java Use Unicode System?

Previous encoding techniques had limitations:

- Different languages use different letters and codes, meaning multiple codes exist for various letters across languages.
- Certain languages have many character sets where the code length varies; some characters use a single byte, others may require two or more bytes.

These challenges motivated the adoption of a **better encoding solution** — the Unicode system.

## What is Unicode System?

The Unicode system is an international character encoding standard designed to represent most languages worldwide.

- Established by the **Unicode Consortium**.
- Uses **hexadecimal values** to represent characters.
- Has multiple encoding formats:
  - **UTF-8**: 8-bit (1 byte) long character encoding.
  - **UTF-16**: 16-bit (2 bytes) long character encoding.
  - **UTF-32**: 32-bit (4 bytes) long character encoding.

Unicode characters can be accessed using an escape sequence `\u` followed by 4 hexadecimal digits.

- Unicode characters range from `\u0000` to `\uFFFF`.

### Examples of Unicode Characters

| Unicode  | Character Description         | Symbol |
| -------- | ----------------------------- | ------ |
| `\u00A9` | Copyright symbol              | ©      |
| `\u0394` | Capital Greek letter delta    | Δ      |
| `\u0022` | Double quote                 | "      |

---

## Java Unicode Example

```java
public class Main {  
   public static void main (String[] args) {            
      // Unicode characters  
      char a = '\u0041';  
      char b = '\u0042';  
  
      // printing unicode  
      System.out.println("a = " + a);  
      System.out.println("b = " + b);  
   }  
}
```
Output:
a = A
b = B
**Program to Convert UTF-8 to Unicode**
```
public class UnicodeDemo {  
   public static void main(String[] args) throws Exception {  
      String str1 = "Unicode Sytem\u00A9";  
      byte[] charset = str1.getBytes("UTF-8");  
      String newstr = new String(charset, "UTF-8");  
      System.out.println(newstr);  
   }  
}
```
Output:
Unicode Sytem©
**Explanation:**

- The string str1 contains a Unicode character (©) represented by \u00A9.

- The string is converted to a UTF-8 byte array using getBytes("UTF-8").

- The byte array is then converted back into a Unicode string using the constructor new String(charset, "UTF-8").

- The final string is printed on the console.

### Problems Caused by Unicode
-  original Unicode standard was designed for 16-bit encoding with the primitive data type char in Java.

- 16 bits can represent 65,536 characters, but this was insufficient for all global characters.

- Unicode was extended to cover up to 1,112,064 characters.

- Characters beyond 16 bits are called Supplementary Characters.

- Java represents supplementary characters using a pair of char values (known as surrogate pairs).

## In this article, we discussed:

Basic methods of encoding

The Unicode System in Java

Problems caused by the Unicode system

Java programs demonstrating the use of Unicode

